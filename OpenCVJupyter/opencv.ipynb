{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to OpenCV & Jupyter\n",
    "Prof. Martin Christen<br/> martin.christen@fhnw.ch<br/>\n",
    "\n",
    "## Installing OpenCV\n",
    "\n",
    "Download latest Anaconda from http://www.anaconda.com/download\n",
    "\n",
    "Open \"anaconda prompt\" and enter:\n",
    "\n",
    "    conda install opencv\n",
    "    \n",
    "## Start Jupyter Lab\n",
    "\n",
    "    jupyter lab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Matplotlib / numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Don't be confused about the version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2. __version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding JupyterHub\n",
    "\n",
    "## What is server, what is client ?\n",
    "\n",
    "\n",
    "#### Example: Get an image from webcam, works only with a local Jupyter!!\n",
    "\n",
    "and store it as image.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "return_value, image = camera.read()\n",
    "cv2.imwrite('images/image.png', image)\n",
    "del camera\n",
    "\n",
    "print(return_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_bgr = cv2.imread('images/image.png',cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_bgr, interpolation = 'bilinear')\n",
    "#plt.xticks([]), plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting BGR to RGB\n",
    "\n",
    "OpenCV uses BGR order for images. Matplotlib uses RGB order.\n",
    "\n",
    "There are two ways to convert it:\n",
    "\n",
    "- splitting channels and merging\n",
    "- converting image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b,g,r = cv2.split(img_bgr)\n",
    "img_rgb = cv2.merge([r,g,b]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying using matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_rgb)\n",
    "plt.xticks([]), plt.yticks([]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a function to show OpenCV images in Jupyter \n",
    "\n",
    "I created a small helper function in cvutils.py you can import it using:\n",
    "\n",
    "    from cvutils import *\n",
    "\n",
    "It converts the array to RGB and displays is. Incase it is only a one channel image, it displays it in grayscale\n",
    "\n",
    "\n",
    "Here is the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(array, figsize=(15,9)):\n",
    "    dim = len(array.shape)\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    if dim == 3:  # BGR-Image\n",
    "        #array_rgb = cv2.cvtColor(array, cv2.COLOR_BGR2RGB)\n",
    "        array_rgb = cv2.cvtColor(array, cv2.CV_32S)\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        return plt.imshow(array_rgb)\n",
    "    elif dim == 2: # grayscale-Image\n",
    "        array_gray = cv2.merge([array,array,array])\n",
    "        plt.xticks([]), plt.yticks([])\n",
    "        return plt.imshow(array_gray, cmap='gray')\n",
    "    else:\n",
    "        print(\"Image now supported:\", dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to open an image as grayscale and in color:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lion_gray = cv2.imread('images/1.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "imshow(lion_gray);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lion_color = cv2.imread('images/1.jpg',cv2.IMREAD_COLOR)\n",
    "imshow(lion_color, figsize=(20,10));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to do some more complex stuff like subplots, you still have to use matplotlib manually:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r,g,b = cv2.split(lion_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "plt.subplot(1,3,1)\n",
    "plt.title(\"Red Channel\")\n",
    "plt.imshow(r, cmap='gray')\n",
    "plt.subplot(1,3,2)\n",
    "plt.title(\"Green Channel\")\n",
    "plt.imshow(g, cmap='gray')\n",
    "plt.subplot(1,3,3)\n",
    "plt.title(\"Blue Channel\")\n",
    "plt.imshow(b, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Cascade Classifier (Haar)\n",
    "\n",
    "* Viola P., Jones M., Robust Real-time Object Detection, IJCV 2001\n",
    "* Lienhart, R. and Maydt, J., An extended set of Haar-like features for rapid object detection, ICIP02, pp. I: 900â€“903, 2002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "people_color = cv2.imread('images/4.jpg',cv2.IMREAD_COLOR)\n",
    "gray = cv2.cvtColor(people_color, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = face_cascade.detectMultiScale(gray, scaleFactor=2.0, minNeighbors=5)\n",
    "print(f\"Detected {len(faces)} faces in image\")\n",
    "for (x,y,w,h) in faces:\n",
    "    cv2.rectangle(people_color,(x,y),(x+w,y+h),(255,0,0),16)\n",
    "    #roi_gray = gray[y:y+h, x:x+w]\n",
    "    #roi_color = people_color[y:y+h, x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(people_color);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Convolution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = cv2.imread('images/2.jpg',cv2.IMREAD_GRAYSCALE)\n",
    "imshow(scene, figsize=(9,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_color = cv2.imread('images/2.jpg',cv2.IMREAD_COLOR)\n",
    "imshow(scene_color, figsize=(9,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sobelY = np.array(([-1, -2, -1],\n",
    "                   [0, 0, 0],\n",
    "                   [1, 2, 1]), dtype=\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_sobelY = cv2.filter2D(scene, -1, sobelY)  # 2. Parameter: Bit-Tiefe (8,16,32. Wenn negativ: gleich wie input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(scene_sobelY, figsize=(9,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blur7 = np.ones((7, 7), dtype=\"float\") * (1.0 / (7 * 7))\n",
    "blur21 = np.ones((21, 21), dtype=\"float\") * (1.0 / (21 * 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_blur7 = cv2.filter2D(scene_color, -1, blur7)\n",
    "imshow(scene_blur7, figsize=(9,6));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_blur21 = cv2.filter2D(scene_color, -1, blur21)\n",
    "imshow(scene_blur21, figsize=(9,6));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More to read:\n",
    "\n",
    "* https://github.com/IBM/powerai-counting-cars/blob/master/notebooks/counting_cars.ipynb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
